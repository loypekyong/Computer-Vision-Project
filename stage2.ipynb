{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":9195731,"sourceType":"datasetVersion","datasetId":5559249},{"sourceId":10125114,"sourceType":"datasetVersion","datasetId":6248060},{"sourceId":10134553,"sourceType":"datasetVersion","datasetId":6254641},{"sourceId":10134693,"sourceType":"datasetVersion","datasetId":6254712},{"sourceId":10135234,"sourceType":"datasetVersion","datasetId":6255069},{"sourceId":192715298,"sourceType":"kernelVersion"},{"sourceId":193161758,"sourceType":"kernelVersion"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:37.289381Z","iopub.execute_input":"2024-12-08T06:24:37.289750Z","iopub.status.idle":"2024-12-08T06:24:37.294316Z","shell.execute_reply.started":"2024-12-08T06:24:37.289717Z","shell.execute_reply":"2024-12-08T06:24:37.293466Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport cv2\nimport numpy as np\nimport os\nimport glob\nimport pydicom","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:37.300948Z","iopub.execute_input":"2024-12-08T06:24:37.301312Z","iopub.status.idle":"2024-12-08T06:24:37.306760Z","shell.execute_reply.started":"2024-12-08T06:24:37.301279Z","shell.execute_reply":"2024-12-08T06:24:37.305833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:37.319684Z","iopub.execute_input":"2024-12-08T06:24:37.320112Z","iopub.status.idle":"2024-12-08T06:24:38.346988Z","shell.execute_reply.started":"2024-12-08T06:24:37.320085Z","shell.execute_reply":"2024-12-08T06:24:38.345796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Combine the 3 files first","metadata":{}},{"cell_type":"code","source":"csv_files = [\n    '/kaggle/input/lsdc-csv-files/output_ss.csv',\n    '/kaggle/input/lsdc-csv-files/output_scs.csv',\n    '/kaggle/input/lsdc-csv-files/output_nfn.csv'\n]\n\ndataframes = []\n\nfor file in csv_files:\n    df = pd.read_csv(file)\n    dataframes.append(df)\n\ncombined_df = pd.concat(dataframes, ignore_index=True)\n\noutput_csv_file = '/kaggle/working/combined_output.csv'\ncombined_df.to_csv(output_csv_file, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:38.349475Z","iopub.execute_input":"2024-12-08T06:24:38.350252Z","iopub.status.idle":"2024-12-08T06:24:39.206623Z","shell.execute_reply.started":"2024-12-08T06:24:38.350207Z","shell.execute_reply":"2024-12-08T06:24:39.205793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Extract images from zip and crop","metadata":{}},{"cell_type":"code","source":"# zip_file_path = '/kaggle/input/lsdc-get-all-images/images.zip'\n# extract_dir = '/kaggle/working/images'\n\n# # Create a directory to extract the images\n# os.makedirs(extract_dir, exist_ok=True)\n\n# # Unzip the file\n# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n#     zip_ref.extractall(extract_dir)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.207806Z","iopub.execute_input":"2024-12-08T06:24:39.208181Z","iopub.status.idle":"2024-12-08T06:24:39.212525Z","shell.execute_reply.started":"2024-12-08T06:24:39.208142Z","shell.execute_reply":"2024-12-08T06:24:39.211655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -rf /kaggle/working/cropped_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.214789Z","iopub.execute_input":"2024-12-08T06:24:39.215048Z","iopub.status.idle":"2024-12-08T06:24:39.224956Z","shell.execute_reply.started":"2024-12-08T06:24:39.215015Z","shell.execute_reply":"2024-12-08T06:24:39.224321Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Download zip file from Kaggle","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.225907Z","iopub.execute_input":"2024-12-08T06:24:39.226233Z","iopub.status.idle":"2024-12-08T06:24:39.236444Z","shell.execute_reply.started":"2024-12-08T06:24:39.226195Z","shell.execute_reply":"2024-12-08T06:24:39.235861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# download_file('/kaggle/input/lsdc-get-all-images/images.zip', 'out')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.237351Z","iopub.execute_input":"2024-12-08T06:24:39.237642Z","iopub.status.idle":"2024-12-08T06:24:39.245824Z","shell.execute_reply.started":"2024-12-08T06:24:39.237618Z","shell.execute_reply":"2024-12-08T06:24:39.245119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n\n# # Create a new ZIP file to download\n# shutil.make_archive('/kaggle/working/downloaded_images', 'zip', extract_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.246725Z","iopub.execute_input":"2024-12-08T06:24:39.246953Z","iopub.status.idle":"2024-12-08T06:24:39.254596Z","shell.execute_reply.started":"2024-12-08T06:24:39.246929Z","shell.execute_reply":"2024-12-08T06:24:39.254009Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create cropped_images","metadata":{}},{"cell_type":"markdown","source":"### Note: Process currently cannot be done in kaggle due to frequent crashing, do in local or elsewhere","metadata":{}},{"cell_type":"code","source":"# import cv2\n# import zipfile\n# from PIL import Image\n# import io\n\n# # Path to the zip file\n# zip_file_path = '/kaggle/input/lsdc-get-all-images/images.zip'\n\n# # Load the CSV file\n# df = pd.read_csv('/kaggle/working/combined_output.csv')\n\n# required_columns = ['image_name', 'x1', 'x2', 'y1', 'y2']\n# if not all(column in df.columns for column in required_columns):\n#     raise ValueError(\"The CSV file is missing required columns.\")\n\n# cropped_dir = '/kaggle/working/cropped_images'\n# if not os.path.exists(cropped_dir):\n#     os.makedirs(cropped_dir)\n\n# invalid_shape_count = 0\n# cropped_size_0 = 0\n# key_error_indices = []\n\n# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n#     for index, row in df.iterrows():\n#         img_name = \"images/\" + row['image_name'].replace('_', '/')\n#         cropped_filename = os.path.join(cropped_dir, os.path.basename(img_name))\n#         re_img_name = row['image_name'].replace('_', '\\\\')\n#         path_name = os.path.join(cropped_dir, str(row['image_name'].replace(\".jpg\", \"\"))+\"@\"+str(row[\"_cls\"]).rsplit(\"_\", 1)[0]+\".jpg\")\n#         # print(cropped_filename, path_name)\n#         # break\n        \n#         if os.path.exists(cropped_filename):\n#             continue \n\n#         try:\n#             with zip_ref.open(img_name) as img_file:\n#                 img = Image.open(img_file)\n#                 img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n\n#             x1, x2, y1, y2 = row['x1'], row['x2'], row['y1'], row['y2']\n\n#             # Check cropping coordinates\n#             if x1 < 0 or x2 > img.shape[1] or y1 < 0 or y2 > img.shape[0]:\n#                 # print(f\"Invalid cropping coordinates for {img_name}: x1={x1}, x2={x2}, y1={y1}, y2={y2}\")\n#                 invalid_shape_count += 1\n#                 continue\n\n#             cropped_img = img[y1:y2, x1:x2]\n\n#             if cropped_img.size == 0:\n#                 # print(f\"Error: Cropped image is empty for {img_name}.\")\n#                 cropped_size_0 += 1\n#                 continue\n#             cv2.imwrite(cropped_filename, cropped_img)  # Save the cropped image using \n#             os.rename(cropped_filename, path_name)\n#             # print(f\"Saved cropped image: {cropped_filename}\")\n\n#         except Exception as e:\n#             # print(f\"Error processing {img_name}: {str(e)}\")\n#             key_error_indices.append(index)\n\n# if key_error_indices:\n#     df_cleaned = df.drop(index=key_error_indices)\n#     new_csv_path = '/kaggle/working/cleaned_combined_output.csv'\n#     df_cleaned.to_csv(new_csv_path, index=False)\n#     print(f\"New CSV file saved without KeyErrors: {new_csv_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.255749Z","iopub.execute_input":"2024-12-08T06:24:39.256014Z","iopub.status.idle":"2024-12-08T06:24:39.265502Z","shell.execute_reply.started":"2024-12-08T06:24:39.255990Z","shell.execute_reply":"2024-12-08T06:24:39.264891Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check for bounding boxes that are invalid","metadata":{}},{"cell_type":"code","source":"# print(len(key_error_indices))\n# print(Invalid_shape_count)\n# print(cropped_size_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.266381Z","iopub.execute_input":"2024-12-08T06:24:39.266626Z","iopub.status.idle":"2024-12-08T06:24:39.277978Z","shell.execute_reply.started":"2024-12-08T06:24:39.266603Z","shell.execute_reply":"2024-12-08T06:24:39.277374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check naming scheme in notebook","metadata":{}},{"cell_type":"code","source":"# zip_file_path = '/kaggle/input/lsdc-get-all-images/images.zip'\n\n# # Open the zip file\n# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n#     # Get the list of all file names in the zip\n#     image_names = zip_ref.namelist()\n\n# # Print the names of the images\n# print(len(image_names))\n# print(image_names[0:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.281015Z","iopub.execute_input":"2024-12-08T06:24:39.281329Z","iopub.status.idle":"2024-12-08T06:24:39.288419Z","shell.execute_reply.started":"2024-12-08T06:24:39.281303Z","shell.execute_reply":"2024-12-08T06:24:39.287792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the CSV file\n# df = pd.read_csv('/kaggle/working/cleaned_combined_output.csv')\n# print(len(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.289298Z","iopub.execute_input":"2024-12-08T06:24:39.289624Z","iopub.status.idle":"2024-12-08T06:24:39.298280Z","shell.execute_reply.started":"2024-12-08T06:24:39.289584Z","shell.execute_reply":"2024-12-08T06:24:39.297447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.299059Z","iopub.execute_input":"2024-12-08T06:24:39.299271Z","iopub.status.idle":"2024-12-08T06:24:39.307119Z","shell.execute_reply.started":"2024-12-08T06:24:39.299249Z","shell.execute_reply":"2024-12-08T06:24:39.306307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     if not \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification\" in dirname:\n#         print(dirname)\n\nfor dirname in os.listdir('/kaggle/input'):\n    full_path = os.path.join('/kaggle/input', dirname)\n    if os.path.isdir(full_path):  # Check if it's a directory\n        print(full_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:24:39.308115Z","iopub.execute_input":"2024-12-08T06:24:39.308345Z","iopub.status.idle":"2024-12-08T06:24:39.328873Z","shell.execute_reply.started":"2024-12-08T06:24:39.308321Z","shell.execute_reply":"2024-12-08T06:24:39.328117Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check sample of cropped images","metadata":{}},{"cell_type":"code","source":"from IPython.display import display\n\n# Directory containing cropped images\ncropped_dir = '/kaggle/input/lsdc-imag-2/cropped_images_2'\ni = 0\n\n\n# Iterate through the cropped images\nfor filename in os.listdir(cropped_dir):\n    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust based on your image format\n        # Load the image\n        img_path = os.path.join(cropped_dir, filename)\n        img = Image.open(img_path)\n        \n        # Display the image\n        # display(img)\n        # print(img_path)\n        i += 1\nprint(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:25:35.947169Z","iopub.execute_input":"2024-12-08T06:25:35.947543Z","iopub.status.idle":"2024-12-08T06:27:10.237618Z","shell.execute_reply.started":"2024-12-08T06:25:35.947508Z","shell.execute_reply":"2024-12-08T06:27:10.236739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print([os.path.join(cropped_dir, filename) for filename in os.listdir(cropped_dir)][3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:27:10.239490Z","iopub.execute_input":"2024-12-08T06:27:10.240089Z","iopub.status.idle":"2024-12-08T06:27:10.264183Z","shell.execute_reply.started":"2024-12-08T06:27:10.240047Z","shell.execute_reply":"2024-12-08T06:27:10.263427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(cropped_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:27:10.290389Z","iopub.execute_input":"2024-12-08T06:27:10.290669Z","iopub.status.idle":"2024-12-08T06:27:10.294827Z","shell.execute_reply.started":"2024-12-08T06:27:10.290644Z","shell.execute_reply":"2024-12-08T06:27:10.293940Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Clean the csv file of invalid samples","metadata":{}},{"cell_type":"code","source":"# Step 1: Load the CSV file\ndf = pd.read_csv('/kaggle/working/combined_output.csv')\n\n# Step 2: List the images in the folder\nimages_folder = '/kaggle/input/lsdc-imag-2/cropped_images_2/'\nimage_files = os.listdir(images_folder)\n\n# Step 3: Create a set of valid image filenames\n# The valid format is: \"image_name@_cls.jpg\"\nvalid_images = image_files\nprint(len(valid_images))\nprint(valid_images[0])\n\ndf['cls_first_part'] = df['_cls'].str.rsplit(\"_\", n=1, expand=True)[0]\n\n# Step 4: Generate the combined image name for each row in the DataFrame\ndf['combined_name'] = df['image_name'].str.replace('.jpg', '') + '@' + df[\"cls_first_part\"] + \".jpg\"\n\n# Step 5: Filter the DataFrame\ncleaned_df = df[df['combined_name'].isin(valid_images)]\nprint(df[\"combined_name\"][0] in valid_images)\n\n# Step 6: Save the cleaned DataFrame\ncleaned_df.to_csv('/kaggle/working/cleaned_output.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:27:18.268885Z","iopub.execute_input":"2024-12-08T06:27:18.269607Z","iopub.status.idle":"2024-12-08T06:27:19.381168Z","shell.execute_reply.started":"2024-12-08T06:27:18.269572Z","shell.execute_reply":"2024-12-08T06:27:19.380442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check if no. rows of csv is equal to no. of cropped images","metadata":{}},{"cell_type":"code","source":"cleaned_df = pd.read_csv('/kaggle/working/cleaned_output.csv')\ncleaned_df.drop(columns=['combined_name', 'cls_first_part'], inplace=True)\nprint(len(cleaned_df))\ndisplay(cleaned_df.head(20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:27:36.093702Z","iopub.execute_input":"2024-12-08T06:27:36.094008Z","iopub.status.idle":"2024-12-08T06:27:36.222237Z","shell.execute_reply.started":"2024-12-08T06:27:36.093980Z","shell.execute_reply":"2024-12-08T06:27:36.221414Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check differences","metadata":{}},{"cell_type":"code","source":"# Step 1: Load both CSV files into DataFrames\noriginal_df = pd.read_csv('/kaggle/working/combined_output.csv')\ncleaned_df = pd.read_csv('/kaggle/working/cleaned_output.csv')\n\n# Step 2: Identify rows that are in the original but not in the cleaned DataFrame\n# You can use the merge function for this purpose\ndiff_original = original_df.merge(cleaned_df, on=list(original_df.columns), how='left', indicator=True)\ndiff_rows = diff_original[diff_original['_merge'] == 'left_only']\n\n# Step 3: Display the differences\nprint(\"Rows in original that are not in cleaned:\")\nprint(diff_rows)\n\n# Optional: Save the differences to a CSV file\ndiff_rows.to_csv('/kaggle/working/differences_output.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:29:13.142594Z","iopub.execute_input":"2024-12-08T06:29:13.143336Z","iopub.status.idle":"2024-12-08T06:29:14.050579Z","shell.execute_reply.started":"2024-12-08T06:29:13.143294Z","shell.execute_reply":"2024-12-08T06:29:14.049792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"difference_df = pd.read_csv(\"/kaggle/working/differences_output.csv\")\ndisplay(difference_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:29:17.558518Z","iopub.execute_input":"2024-12-08T06:29:17.559089Z","iopub.status.idle":"2024-12-08T06:29:17.711049Z","shell.execute_reply.started":"2024-12-08T06:29:17.559046Z","shell.execute_reply":"2024-12-08T06:29:17.710195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(i)\nprint(len(cleaned_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:29:20.539597Z","iopub.execute_input":"2024-12-08T06:29:20.539906Z","iopub.status.idle":"2024-12-08T06:29:20.544703Z","shell.execute_reply.started":"2024-12-08T06:29:20.539879Z","shell.execute_reply":"2024-12-08T06:29:20.543693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ndf = cleaned_df\n\n# Split the '_cls' column into two parts\ndf['target'] = df['_cls'].str.rsplit('_', n=1).str[-1]\ndf['_cls'] = df['_cls'].str.rsplit('_', n=1).str[0]\n\ndisplay(df.head())\n\n# Rearrange the DataFrame\n# df = df[['image_name', '_cls', 'x1', 'x2', 'y1', 'y2', 'target']]\n\n# Save the modified DataFrame to a new CSV file\ndf.to_csv('/kaggle/working/modified_file.csv', index=False)  # Use the desired separator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:29:33.196186Z","iopub.execute_input":"2024-12-08T06:29:33.196506Z","iopub.status.idle":"2024-12-08T06:29:33.635374Z","shell.execute_reply.started":"2024-12-08T06:29:33.196478Z","shell.execute_reply":"2024-12-08T06:29:33.634453Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Final dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/modified_file.csv')\ndisplay(df.head())\nprint(df[\"target\"].unique())\nprint(len(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:29:46.306321Z","iopub.execute_input":"2024-12-08T06:29:46.307110Z","iopub.status.idle":"2024-12-08T06:29:46.459710Z","shell.execute_reply.started":"2024-12-08T06:29:46.307075Z","shell.execute_reply":"2024-12-08T06:29:46.458909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"combined_name\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:33:07.492740Z","iopub.execute_input":"2024-12-08T06:33:07.493036Z","iopub.status.idle":"2024-12-08T06:33:07.498638Z","shell.execute_reply.started":"2024-12-08T06:33:07.493009Z","shell.execute_reply":"2024-12-08T06:33:07.497659Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Start training phase","metadata":{}},{"cell_type":"markdown","source":"### Create dataloader object","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nfrom PIL import Image\n\n# Define a custom dataset class\nclass LumbarSpineDataset(Dataset):\n    def __init__(self, df, transform):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        img_path = '/kaggle/input/lsdc-imag-2/cropped_images_2/' + self.df.iloc[index]['combined_name']\n        label = self.df.iloc[index]['target']\n\n        img = Image.open(img_path)\n        img = self.transform(img)\n\n        # Map the label to a numerical value cus easier for classification model\n        label_map = {'normal/mild': 0, 'moderate': 1, 'severe': 2}\n        label = label_map[label]\n\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:37:40.947334Z","iopub.execute_input":"2024-12-08T06:37:40.948150Z","iopub.status.idle":"2024-12-08T06:37:40.954242Z","shell.execute_reply.started":"2024-12-08T06:37:40.948115Z","shell.execute_reply":"2024-12-08T06:37:40.953297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the data into training and validation sets\n# Use sklearn to split\nfrom sklearn.model_selection import train_test_split\n\n# We use 0.01 since we have a lot of samples\ntrain_df, val_df = train_test_split(df, test_size=0.01, random_state=42)\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create the dataset instances\ntrain_dataset = LumbarSpineDataset(train_df, transform)\nval_dataset = LumbarSpineDataset(val_df, transform)\n\n# Create the data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:37:41.345704Z","iopub.execute_input":"2024-12-08T06:37:41.346483Z","iopub.status.idle":"2024-12-08T06:37:41.361587Z","shell.execute_reply.started":"2024-12-08T06:37:41.346447Z","shell.execute_reply":"2024-12-08T06:37:41.360589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"model = resnet50(pretrained=True)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Move the model to the device\nmodel.to(device)\n\n# Freeze the model weights to reduce training time\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Add a custom classification head for the 3 outputs\n# ResNet50 outputs 2048 features\nmodel.fc = nn.Linear(2048, 3)  \n\n# Set the model to the device\nmodel.fc.to(device)\n\n# Define the criterion and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n\n# Training loop\nfor epoch in range(10):\n    model.train()\n    for batch in train_loader:\n        inputs, labels = batch\n        inputs, labels = inputs.to(device), labels.to(device)  # Ensure inputs and labels are on the same device\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    # Validation loop\n    model.eval()\n    val_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs, labels = batch\n            inputs, labels = inputs.to(device), labels.to(device)  # Ensure inputs and labels are on the same device\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / len(val_loader.dataset)\n    print(f'Epoch {epoch+1}, Val Loss: {val_loss / len(val_loader)}, Val Acc: {accuracy:.4f}')\n\n# Save the model\ntorch.save(model.state_dict(), 'lsdc_resnet50_model1.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:37:42.255120Z","iopub.execute_input":"2024-12-08T06:37:42.255737Z","iopub.status.idle":"2024-12-08T07:15:53.109429Z","shell.execute_reply.started":"2024-12-08T06:37:42.255702Z","shell.execute_reply":"2024-12-08T07:15:53.108478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T07:15:53.111289Z","iopub.execute_input":"2024-12-08T07:15:53.111975Z","iopub.status.idle":"2024-12-08T07:15:53.116829Z","shell.execute_reply.started":"2024-12-08T07:15:53.111927Z","shell.execute_reply":"2024-12-08T07:15:53.115933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}